{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    },
    "colab": {
      "name": "TPOT_tutorial_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b78f0ff7621f43159a22b236f40bd085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f6a8958ecdc4639a23d106df60f5840",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f9fb5b9cc1443ecb895689fd05909f6",
              "IPY_MODEL_cca6e82465834f01a668df24b4eeac69"
            ]
          }
        },
        "4f6a8958ecdc4639a23d106df60f5840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f9fb5b9cc1443ecb895689fd05909f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ae9533c8af14d57ba9309f9a81a2c61",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa99bdb4f80f4cbb8f20f07744f47a10"
          }
        },
        "cca6e82465834f01a668df24b4eeac69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_955caec31192418c868f95c94dc5cb83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 600/600 [3:04:28&lt;00:00, 19.31s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adc5347f1340483493c2c92031bddb8d"
          }
        },
        "5ae9533c8af14d57ba9309f9a81a2c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa99bdb4f80f4cbb8f20f07744f47a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "955caec31192418c868f95c94dc5cb83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adc5347f1340483493c2c92031bddb8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOlWS3SwJ0CQ",
        "colab_type": "text"
      },
      "source": [
        "# TPOT in Python\n",
        "\n",
        "In this tutorial, you will learn how to use a very unique library in python: `TPOT`. The reason why this library is unique is that it automates the entire Machine Learning pipeline and provides you with the best performing machine learning model. `TPOT` is one of the most popular package in Automated Machine Learning (AutoML) - since it is effective and free to use.\n",
        "\n",
        "More specifically, you will learn:\n",
        "\n",
        "- The idea behind Automated Machine Learning\n",
        "- How TPOT uses Genetic Programming to select the best machine learning model\n",
        "- Using TPOT on a dataset in Python\n",
        "- Limitations of TPOT\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "Original post is [here](https://www.datacamp.com/community/tutorials/tpot-machine-learning-python) - many thanks to DataCamp!\n",
        "\n",
        "Revised by Dr. Jie Tao, Mar-31-2020, Ver. 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x61_wM-xJ0CR",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "There are a lot of components you have to consider before solving a machine learning problem some of which includes *data preparation*, *feature selection*, *feature engineering*, *model selection and validation*, *hyperparameter tuning*, etc. \n",
        "\n",
        "In theory, you can find and apply a plethora of techniques for each of these components, but they all might perform differently for different datasets. The challenge is to find the best performing combination of techniques so that you can minimize the error in your predictions. This is the main reason that nowadays people are working to develop **Auto-ML algorithms** and platforms so that anyone, without any machine learning expertise, can build models without spending much time or effort. \n",
        "\n",
        "One such platform is available as a python library: **TPOT**. You can consider **TPOT** your Data Science Assistant. TPOT is a python Automated Machine Learning tool that optimizes *machine learning pipelines* using genetic programming. It will automate the most tedious part of machine learning by intelligently exploring thousands of possible pipelines to find the best one for your data.\n",
        "\n",
        "Following image depicts how TPOT works:\n",
        "\n",
        "<img src = 'https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1537396029/output_2_0_d7uh0v.png'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVLHyLJUJ0CR",
        "colab_type": "text"
      },
      "source": [
        "# Installation\n",
        "To install tpot on your system, you can run the command **sudo pip install tpot** on command line terminal or check out this [link](http://epistasislab.github.io/tpot/installing/). tpot is built on top of several existing Python libraries, including **numpy**, **scipy**, **scikit-learn**, **DEAP**, **update_checker**, **tqdm**, **stopit**, and **pandas**. Most of the necessary Python packages can be installed via the [Anaconda Python distribution](https://www.continuum.io/downloads), or you could install them separately also. Optionally, you can also install **XGBoost** [here](https://www.datacamp.com/community/tutorials/xgboost-in-python) if you would like tpot to use the eXtreme Gradient Boosting models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P6sKu1RJ0CS",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Programming\n",
        "With the right data, computing power and machine learning model you can discover a solution to any problem, but knowing which model to use can be challenging for you as there are so many of them like *Decision Trees*, *SVM*, *KNN*, etc. That's where genetic programming can be of great use and provide help. Genetic algorithms are inspired by the Darwinian process of Natural Selection, and they are used to generate solutions to optimization and search problems in computer science.\n",
        "\n",
        "Broadly speaking, Genetic Algorithms have three properties:\n",
        "\n",
        "- Selection: You have a population of possible solutions to a given problem and a fitness function. At every iteration, you evaluate how to fit each solution with your fitness function.\n",
        "- Crossover: Then you select the fittest ones and perform crossover to create a new population.\n",
        "- Mutation: You take those children and mutate them with some random modification and repeat the process until you get the fittest or best solution.\n",
        "\n",
        "Genetic Programming itself is a big topic in computer science but if you wish to go deeper into genetic algorithms, check out this video series.\n",
        "\n",
        "***But how does this all fit into data science?***\n",
        "\n",
        "Well, it turns out that choosing the right machine learning model and all the best hyperparameters for that model is itself an optimization problem for which genetic programming can be used. The Python library tpot built on top of scikit-learn uses genetic programming to optimize your machine learning pipeline. For instance, in machine learning, after preparing your data you need to know what features to input to your model and how you should construct those features. Once you have those features, you input them into your model to train on, and then you tune your hyperparameters to get the optimal results. Instead of doing this all by yourselves through trial and error, TPOT automates these steps for you with genetic programming and outputs the optimal code for you when it's done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OkCt1cDJ0CS",
        "colab_type": "text"
      },
      "source": [
        "# A Running Example\n",
        "\n",
        "\n",
        "To understand further, you will practice using the tpot library on an open source dataset. The dataset you will be using is MAGIC Gamma Telescope DataSet. The data are generated to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. The dataset has the following attributes/features :\n",
        "\n",
        "**Predictors**\n",
        "\n",
        "1. fLength: continuous *# major axis of ellipse [mm]*\n",
        "2. fWidth: continuous *# minor axis of ellipse [mm]*\n",
        "3. fSize: continuous *# 10-log of sum of content of all pixels [in #phot]*\n",
        "4. fConc: continuous *# ratio of sum of two highest pixels over fSize [ratio]*\n",
        "5. fConc1: continuous *# ratio of highest pixel over fSize [ratio]*\n",
        "6. fAsym: continuous *# distance from the highest pixel to center, projected onto major axis [mm]*\n",
        "7. fM3Long: continuous *# 3rd root of the third moment along major axis [mm]*\n",
        "8. fM3Trans: continuous *# 3rd root of the third moment along minor axis [mm]*\n",
        "9. fAlpha: continuous *# angle of major axis with a vector to origin [deg]*\n",
        "10. fDist: continuous *# distance from the origin to the center of the ellipse [mm]*\n",
        "\n",
        "**Target**\n",
        "\n",
        "11. class: g,h *# gamma (signal), hadron (background) (target variable)*\n",
        "\n",
        "The goal is to classify an observation as *gamma*, which is the desired signal, or *hadron*, which is the background noise, based on the attributes provided.\n",
        "\n",
        "You will start by importing **pandas** and **numpy** libraries to read the data and perform computations on it respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPxzAslnJ0CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mST5XGMEJ0CW",
        "colab_type": "text"
      },
      "source": [
        "## Read-in Data\n",
        "\n",
        "Use the pandas **read_csv()** function to read the dataset as a DataFrame. Also, specify the parameter **header = None** since the dataset doesn't have column names yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94SmLSq5J0CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/fairfield-university-ba545/Week11/master/data/magic04.csv'\n",
        "telescope_data=pd.read_csv(data_url,header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xayO11vYJ0CY",
        "colab_type": "text"
      },
      "source": [
        "Check the contents of the DataFrame using the **head()** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJj3XsXwJ0CY",
        "colab_type": "code",
        "outputId": "b260a2c4-a243-4405-9d30-95b8f5d7a2de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "telescope_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.7967</td>\n",
              "      <td>16.0021</td>\n",
              "      <td>2.6449</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.1982</td>\n",
              "      <td>27.7004</td>\n",
              "      <td>22.0110</td>\n",
              "      <td>-8.2027</td>\n",
              "      <td>40.0920</td>\n",
              "      <td>81.8828</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1       2       3   ...       7        8         9   10\n",
              "0   28.7967   16.0021  2.6449  0.3918  ...  -8.2027  40.0920   81.8828   g\n",
              "1   31.6036   11.7235  2.5185  0.5303  ...  -9.9574   6.3609  205.2610   g\n",
              "2  162.0520  136.0310  4.0612  0.0374  ... -45.2160  76.9600  256.7880   g\n",
              "3   23.8172    9.5728  2.3385  0.6147  ...  -7.1513  10.4490  116.7370   g\n",
              "4   75.1362   30.9205  3.1611  0.3168  ...  21.8393   4.6480  356.4620   g\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY5c5FnOJ0Cb",
        "colab_type": "text"
      },
      "source": [
        "To give names to the columns of the DataFrame, you can use the attribute columns on the pandas DataFrame and assign it to a list containing the names of the columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWHEXoqyJ0Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "telescope_data.columns = ['fLength', 'fWidth','fSize','fConc','fConcl','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzUPu5YoJ0Cd",
        "colab_type": "code",
        "outputId": "b07801d1-02bc-4993-ddda-bb4e702c53d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "telescope_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConcl</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.7967</td>\n",
              "      <td>16.0021</td>\n",
              "      <td>2.6449</td>\n",
              "      <td>0.3918</td>\n",
              "      <td>0.1982</td>\n",
              "      <td>27.7004</td>\n",
              "      <td>22.0110</td>\n",
              "      <td>-8.2027</td>\n",
              "      <td>40.0920</td>\n",
              "      <td>81.8828</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fLength    fWidth   fSize   fConc  ...  fM3Trans   fAlpha     fDist  class\n",
              "0   28.7967   16.0021  2.6449  0.3918  ...   -8.2027  40.0920   81.8828      g\n",
              "1   31.6036   11.7235  2.5185  0.5303  ...   -9.9574   6.3609  205.2610      g\n",
              "2  162.0520  136.0310  4.0612  0.0374  ...  -45.2160  76.9600  256.7880      g\n",
              "3   23.8172    9.5728  2.3385  0.6147  ...   -7.1513  10.4490  116.7370      g\n",
              "4   75.1362   30.9205  3.1611  0.3168  ...   21.8393   4.6480  356.4620      g\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1qyi0vQJ0Cg",
        "colab_type": "text"
      },
      "source": [
        "Now you have the column names as well in your DataFrame.\n",
        "\n",
        "# Investigating Your Data\n",
        "To get the necessary information about the DataFrame like the number of values in each column, data-type, count, mean, etc., you can use the pandas info() and describe() methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5Q4IKeJ0Cg",
        "colab_type": "code",
        "outputId": "5aa2fa1e-eba0-4662-ec6c-4f7ced4c3533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "telescope_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19020 entries, 0 to 19019\n",
            "Data columns (total 11 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   fLength   19020 non-null  float64\n",
            " 1   fWidth    19020 non-null  float64\n",
            " 2   fSize     19020 non-null  float64\n",
            " 3   fConc     19020 non-null  float64\n",
            " 4   fConcl    19020 non-null  float64\n",
            " 5   fAsym     19020 non-null  float64\n",
            " 6   fM3Long   19020 non-null  float64\n",
            " 7   fM3Trans  19020 non-null  float64\n",
            " 8   fAlpha    19020 non-null  float64\n",
            " 9   fDist     19020 non-null  float64\n",
            " 10  class     19020 non-null  object \n",
            "dtypes: float64(10), object(1)\n",
            "memory usage: 1.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm7HeyX2J0Ci",
        "colab_type": "code",
        "outputId": "ae8fd573-9c38-42cd-95ed-74964e0faecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "telescope_data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConcl</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "      <td>19020.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>53.250154</td>\n",
              "      <td>22.180966</td>\n",
              "      <td>2.825017</td>\n",
              "      <td>0.380327</td>\n",
              "      <td>0.214657</td>\n",
              "      <td>-4.331745</td>\n",
              "      <td>10.545545</td>\n",
              "      <td>0.249726</td>\n",
              "      <td>27.645707</td>\n",
              "      <td>193.818026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>42.364855</td>\n",
              "      <td>18.346056</td>\n",
              "      <td>0.472599</td>\n",
              "      <td>0.182813</td>\n",
              "      <td>0.110511</td>\n",
              "      <td>59.206062</td>\n",
              "      <td>51.000118</td>\n",
              "      <td>20.827439</td>\n",
              "      <td>26.103621</td>\n",
              "      <td>74.731787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.283500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.941300</td>\n",
              "      <td>0.013100</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>-457.916100</td>\n",
              "      <td>-331.780000</td>\n",
              "      <td>-205.894700</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.282600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24.336000</td>\n",
              "      <td>11.863800</td>\n",
              "      <td>2.477100</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>0.128475</td>\n",
              "      <td>-20.586550</td>\n",
              "      <td>-12.842775</td>\n",
              "      <td>-10.849375</td>\n",
              "      <td>5.547925</td>\n",
              "      <td>142.492250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.147700</td>\n",
              "      <td>17.139900</td>\n",
              "      <td>2.739600</td>\n",
              "      <td>0.354150</td>\n",
              "      <td>0.196500</td>\n",
              "      <td>4.013050</td>\n",
              "      <td>15.314100</td>\n",
              "      <td>0.666200</td>\n",
              "      <td>17.679500</td>\n",
              "      <td>191.851450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.122175</td>\n",
              "      <td>24.739475</td>\n",
              "      <td>3.101600</td>\n",
              "      <td>0.503700</td>\n",
              "      <td>0.285225</td>\n",
              "      <td>24.063700</td>\n",
              "      <td>35.837800</td>\n",
              "      <td>10.946425</td>\n",
              "      <td>45.883550</td>\n",
              "      <td>240.563825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>334.177000</td>\n",
              "      <td>256.382000</td>\n",
              "      <td>5.323300</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.675200</td>\n",
              "      <td>575.240700</td>\n",
              "      <td>238.321000</td>\n",
              "      <td>179.851000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>495.561000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            fLength        fWidth  ...        fAlpha         fDist\n",
              "count  19020.000000  19020.000000  ...  19020.000000  19020.000000\n",
              "mean      53.250154     22.180966  ...     27.645707    193.818026\n",
              "std       42.364855     18.346056  ...     26.103621     74.731787\n",
              "min        4.283500      0.000000  ...      0.000000      1.282600\n",
              "25%       24.336000     11.863800  ...      5.547925    142.492250\n",
              "50%       37.147700     17.139900  ...     17.679500    191.851450\n",
              "75%       70.122175     24.739475  ...     45.883550    240.563825\n",
              "max      334.177000    256.382000  ...     90.000000    495.561000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-BRiEUqJ0Ck",
        "colab_type": "text"
      },
      "source": [
        "Turns out all the features in the DataFrame are continuous in nature. The target variable/feature class is however *categorical*. You can check the counts of each class in the target variable using **value_counts()** method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8cEaapJ0Cl",
        "colab_type": "code",
        "outputId": "0eb28005-67a7-4ef3-f10b-25e8a6a5065c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "telescope_data['class'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "g    12332\n",
              "h     6688\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHPBGktyJ0Cm",
        "colab_type": "text"
      },
      "source": [
        "It's generally a good idea to randomly **shuffle** the data before starting to avoid any type of ordering in the data. You can rearrange the data in the DataFrame using numpy's **random** and **permutation()** function. To reset the index numbers after the shuffle use **reset_index()** method with **drop = True** as a parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi1MhbJ8J0Cn",
        "colab_type": "code",
        "outputId": "1e8d8eb5-9704-47e2-967f-38154c36c71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "telescope_shuffle=telescope_data.iloc[np.random.permutation(len(telescope_data))]\n",
        "tele=telescope_shuffle.reset_index(drop=True)\n",
        "tele.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConcl</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87.2570</td>\n",
              "      <td>23.2826</td>\n",
              "      <td>3.0183</td>\n",
              "      <td>0.2167</td>\n",
              "      <td>0.1146</td>\n",
              "      <td>-31.4565</td>\n",
              "      <td>68.7719</td>\n",
              "      <td>-4.4924</td>\n",
              "      <td>2.3986</td>\n",
              "      <td>297.9090</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.4792</td>\n",
              "      <td>24.3384</td>\n",
              "      <td>2.4031</td>\n",
              "      <td>0.6522</td>\n",
              "      <td>0.3379</td>\n",
              "      <td>-30.0060</td>\n",
              "      <td>-21.9428</td>\n",
              "      <td>18.6641</td>\n",
              "      <td>11.0181</td>\n",
              "      <td>314.8710</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.2371</td>\n",
              "      <td>19.4698</td>\n",
              "      <td>2.9393</td>\n",
              "      <td>0.2691</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>-18.0537</td>\n",
              "      <td>-17.9550</td>\n",
              "      <td>-8.4689</td>\n",
              "      <td>8.6172</td>\n",
              "      <td>140.5940</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81.6368</td>\n",
              "      <td>25.1357</td>\n",
              "      <td>2.4476</td>\n",
              "      <td>0.4251</td>\n",
              "      <td>0.2132</td>\n",
              "      <td>-96.2788</td>\n",
              "      <td>37.9453</td>\n",
              "      <td>7.9119</td>\n",
              "      <td>18.7284</td>\n",
              "      <td>328.0580</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>205.1280</td>\n",
              "      <td>176.3350</td>\n",
              "      <td>4.9946</td>\n",
              "      <td>0.0139</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>8.5005</td>\n",
              "      <td>-79.1621</td>\n",
              "      <td>83.2966</td>\n",
              "      <td>76.3946</td>\n",
              "      <td>41.4222</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fLength    fWidth   fSize   fConc  ...  fM3Trans   fAlpha     fDist  class\n",
              "0   87.2570   23.2826  3.0183  0.2167  ...   -4.4924   2.3986  297.9090      g\n",
              "1   28.4792   24.3384  2.4031  0.6522  ...   18.6641  11.0181  314.8710      g\n",
              "2   38.2371   19.4698  2.9393  0.2691  ...   -8.4689   8.6172  140.5940      g\n",
              "3   81.6368   25.1357  2.4476  0.4251  ...    7.9119  18.7284  328.0580      h\n",
              "4  205.1280  176.3350  4.9946  0.0139  ...   83.2966  76.3946   41.4222      g\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj0rS3uhJ0Cr",
        "colab_type": "text"
      },
      "source": [
        "### Label Your Target\n",
        "\n",
        "Before using tpot, it is essential you do the labeling of categorical variables in your DataFrame. To learn more about labeling categorical variables check out this tutorial. Here only the target variable class is the *categorical* feature, hence the treatment should be done to that column. \n",
        "\n",
        "You will replace the **g** class (signal) with a numerical value **0** and **h** class (background) with numerical value **1**. This can be achieved via **map()** function with the argument as a dictionary which holds the respective mapping of the classes of the target variable.\n",
        "\n",
        "**NOTE:** in practice, this is usually done by the [label encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) or [one-hot encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) provided with scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3KKoZxYJ0Cr",
        "colab_type": "code",
        "outputId": "7a8bd445-f99b-415d-b028-339123166246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tele['class']=tele['class'].map({'g':0,'h':1})\n",
        "tele.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fLength</th>\n",
              "      <th>fWidth</th>\n",
              "      <th>fSize</th>\n",
              "      <th>fConc</th>\n",
              "      <th>fConcl</th>\n",
              "      <th>fAsym</th>\n",
              "      <th>fM3Long</th>\n",
              "      <th>fM3Trans</th>\n",
              "      <th>fAlpha</th>\n",
              "      <th>fDist</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87.2570</td>\n",
              "      <td>23.2826</td>\n",
              "      <td>3.0183</td>\n",
              "      <td>0.2167</td>\n",
              "      <td>0.1146</td>\n",
              "      <td>-31.4565</td>\n",
              "      <td>68.7719</td>\n",
              "      <td>-4.4924</td>\n",
              "      <td>2.3986</td>\n",
              "      <td>297.9090</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.4792</td>\n",
              "      <td>24.3384</td>\n",
              "      <td>2.4031</td>\n",
              "      <td>0.6522</td>\n",
              "      <td>0.3379</td>\n",
              "      <td>-30.0060</td>\n",
              "      <td>-21.9428</td>\n",
              "      <td>18.6641</td>\n",
              "      <td>11.0181</td>\n",
              "      <td>314.8710</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.2371</td>\n",
              "      <td>19.4698</td>\n",
              "      <td>2.9393</td>\n",
              "      <td>0.2691</td>\n",
              "      <td>0.1593</td>\n",
              "      <td>-18.0537</td>\n",
              "      <td>-17.9550</td>\n",
              "      <td>-8.4689</td>\n",
              "      <td>8.6172</td>\n",
              "      <td>140.5940</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>81.6368</td>\n",
              "      <td>25.1357</td>\n",
              "      <td>2.4476</td>\n",
              "      <td>0.4251</td>\n",
              "      <td>0.2132</td>\n",
              "      <td>-96.2788</td>\n",
              "      <td>37.9453</td>\n",
              "      <td>7.9119</td>\n",
              "      <td>18.7284</td>\n",
              "      <td>328.0580</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>205.1280</td>\n",
              "      <td>176.3350</td>\n",
              "      <td>4.9946</td>\n",
              "      <td>0.0139</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>8.5005</td>\n",
              "      <td>-79.1621</td>\n",
              "      <td>83.2966</td>\n",
              "      <td>76.3946</td>\n",
              "      <td>41.4222</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    fLength    fWidth   fSize   fConc  ...  fM3Trans   fAlpha     fDist  class\n",
              "0   87.2570   23.2826  3.0183  0.2167  ...   -4.4924   2.3986  297.9090      0\n",
              "1   28.4792   24.3384  2.4031  0.6522  ...   18.6641  11.0181  314.8710      0\n",
              "2   38.2371   19.4698  2.9393  0.2691  ...   -8.4689   8.6172  140.5940      0\n",
              "3   81.6368   25.1357  2.4476  0.4251  ...    7.9119  18.7284  328.0580      1\n",
              "4  205.1280  176.3350  4.9946  0.0139  ...   83.2966  76.3946   41.4222      0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YUIaadoJ0Ct",
        "colab_type": "text"
      },
      "source": [
        "Now you store the class labels, which you need to predict, in a separate variable *tele_class*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6io8HP7J0Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tele_class = tele['class'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLkpxruCJ0Cv",
        "colab_type": "text"
      },
      "source": [
        "### MIssing Value Handling\n",
        "\n",
        "You should also do missing value treatment before using *tpot*. To check the number of missing values column-wise, you can execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M9N8vfCJ0Cw",
        "colab_type": "code",
        "outputId": "b5e99e4c-1680-4d54-a354-4bef89f286d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "pd.isnull(tele).any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fLength     False\n",
              "fWidth      False\n",
              "fSize       False\n",
              "fConc       False\n",
              "fConcl      False\n",
              "fAsym       False\n",
              "fM3Long     False\n",
              "fM3Trans    False\n",
              "fAlpha      False\n",
              "fDist       False\n",
              "class       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sp8XVhRJ0Cx",
        "colab_type": "text"
      },
      "source": [
        "This dataset doesn't have any missing values. Note in datasets with missing values you can either drop the rows/columns using dropna() method or replace the missing value with some dummy value using fillna() method. For example, the following chunk of code will replace the NA values with a dummy value -999."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mZatlaBJ0Cy",
        "colab_type": "raw"
      },
      "source": [
        "tele = tele.fillna(-999)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHCCtk8KJ0Cy",
        "colab_type": "text"
      },
      "source": [
        "You will now split the DataFrame into a training set and a testing set just like you do while doing any type of machine learning modeling. You can do this via sklearn's **cross_validation** **train_test_split**. The parameters are tele.index as indexes of the DataFrame, *train_size = 0.75* to keep 75% of the data in training set, *test_size = 0.25* to keep the rest 25% data in testing set and stratify = tele_class the class label's values in the dataset. Note the validation set is just to give us an idea of the test set error. Here it is kept to be the same as a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXHzw1SjJ0Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_indices, testing_indices = train_test_split(tele.index,\n",
        "                                                        stratify = tele_class,\n",
        "                                                        train_size=0.75, test_size=0.25, random_state = 2019)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntNQ4-CkJ0C0",
        "colab_type": "text"
      },
      "source": [
        "You can check the size of the training set and validation set using the size attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKQlGFLiJ0C1",
        "colab_type": "code",
        "outputId": "c3c4aa3c-0d61-4f30-b50a-4ee2c96c9cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_indices.size, testing_indices.size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14265, 4755)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6oj4kkkJ0C3",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to use the **tpot** library to suggest us the best pipeline for this binary classification problem. To do so, you have to import **TPOTClassifier** class from the tpot library. Had this been a regression problem you would have imported **TPOTRegressor** class.\n",
        "\n",
        "**TPOTClassifier** has a wide variety of parameters, and you can read all about them here. But the most notable ones you must know are:\n",
        "\n",
        "- generations: Number of iterations to the run pipeline optimization process. The default is 100.\n",
        "- population_size: Number of individuals to retain in the genetic programming population every generation. The default is 100.\n",
        "- offspring_size: Number of offspring to produce in each genetic programming generation. The default is 100.\n",
        "- mutation_rate: Mutation rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the GP algorithm how many pipelines to apply random changes to every generation. Default is 0.9\n",
        "- crossover_rate: Crossover rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the genetic programming algorithm how many pipelines to \"breed\" every generation.\n",
        "- scoring: Function used to evaluate the quality of a given pipeline for the classification problem like accuracy, average_precision, roc_auc, recall, etc. The default is accuracy.\n",
        "- cv: Cross-validation strategy used when evaluating pipelines. The default is 5.\n",
        "- random_state: The seed of the pseudo-random number generator used in TPOT. Use this parameter to make sure that TPOT will give you the same results each time you run it against the same data set with that seed.\n",
        "\n",
        "Also note mutation_rate + crossover_rate cannot exceed **1.0**.\n",
        "\n",
        "Here you will use tpot with generations = 5 and the rest of the parameters at default values. The parameter verbosity = 2 states how much information TPOT communicates while it's running.\n",
        "\n",
        "Then you will call the **fit()** method with the training set (without the target column) and the target column as the arguments.\n",
        "\n",
        "Note running the code in the below cell will take several hours to finish. With the given TPOT settings (5 generations with 100 population size), TPOT will evaluate 500 pipeline configurations before finishing. To put this number into context, think about a grid search of 500 hyperparameter combinations for a machine learning algorithm and how long that grid search will take. That is 500 model configurations to evaluate with 5-fold cross-validation, which means that roughly 2500 models are fit and evaluated on the training data in one grid search. That's a time-consuming procedure! Later, you will get to know about some more arguments that you can pass to TPOTClassifier to control the execution time for TPOT to finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n76X7LrmKn4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### install TPOT\n",
        "# !pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTFtQBPkJ0C3",
        "colab_type": "code",
        "outputId": "60e48efe-737f-4db7-d7fa-a8a5f9aa97a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "b78f0ff7621f43159a22b236f40bd085",
            "4f6a8958ecdc4639a23d106df60f5840",
            "5f9fb5b9cc1443ecb895689fd05909f6",
            "cca6e82465834f01a668df24b4eeac69",
            "5ae9533c8af14d57ba9309f9a81a2c61",
            "fa99bdb4f80f4cbb8f20f07744f47a10",
            "955caec31192418c868f95c94dc5cb83",
            "adc5347f1340483493c2c92031bddb8d"
          ]
        }
      },
      "source": [
        "from tpot import TPOTClassifier\n",
        "# from tpot import TPOTRegressor # for regression tasks\n",
        "\n",
        "tpot = TPOTClassifier(generations=5,verbosity=2)\n",
        "\n",
        "tpot.fit(tele.drop('class',axis=1).loc[training_indices].values, # X_train\n",
        "         tele.loc[training_indices,'class'].values) # y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b78f0ff7621f43159a22b236f40bd085",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=600, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.8737469330529268\n",
            "Generation 2 - Current best internal CV score: 0.8790746582544691\n",
            "Generation 3 - Current best internal CV score: 0.880266386260077\n",
            "Generation 4 - Current best internal CV score: 0.880266386260077\n",
            "Generation 5 - Current best internal CV score: 0.880266386260077\n",
            "\n",
            "Best pipeline: RandomForestClassifier(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), bootstrap=True, criterion=gini, max_features=0.45, min_samples_leaf=2, min_samples_split=13, n_estimators=100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "               disable_update_check=False, early_stop=None, generations=5,\n",
              "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "               periodic_checkpoint_folder=None, population_size=100,\n",
              "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
              "               use_dask=False, verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_PuFq4KJ0C5",
        "colab_type": "text"
      },
      "source": [
        "In the above, 5 generations were computed, each giving the training efficiency of the fitting model on the training set. As evident, the best pipeline is the one that has the CV accuracy score of **88.12%**. The model that produces this result is the pipeline, consisting of pre-processing techniques like `PloynomialFeatures` and then `RobustScaler` that adds synthetic features to the input data and normalizes them, which then get utilized by a Gradient Boosting classifier to form the final predictions. You can also notice that tpot gives various hyper-parameter values like `learning_rate`, `max_depth`, etc., also along with the classifier.\n",
        "\n",
        "One of the key difference here is we use both `X_test` and `y_test` in the code below, since the `.score()` method below combines the __prediction__ and __evaluation__ in the same step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPssRymIJ0C5",
        "colab_type": "code",
        "outputId": "0bc5a3aa-6335-4118-b020-22150a0737b3",
        "colab": {}
      },
      "source": [
        "tpot.score(tele.drop('class',axis=1).loc[testing_indices].values, #X_test\n",
        "           tele.loc[testing_indices, 'class'].values) # y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88012618296529965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJNkLHsJ0C7",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the test accuracy is **88.14%.**\n",
        "\n",
        "Finally, you can tell TPOT to export the corresponding Python code for the optimized pipeline to a text file with the export function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msHj2rKhJ0C7",
        "colab_type": "raw"
      },
      "source": [
        "tpot.export('tpot_MAGIC_Gamma_Telescope_pipeline.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEy3t7mKJ0C7",
        "colab_type": "text"
      },
      "source": [
        "Isn't that awesome? Without you tweaking a lot of parameters and options to get the best model, TPOT not only gave you the information about the best model but also a working code for it!\n",
        "\n",
        "As indicated earlier, the last TPOT run took *several hours* to finish. Well, there are certain parameters you can specify to control the execution time of TPOT but with a trade-off. Since you will be limiting the time of TPOT execution, TPOT won't be able to explore all the possible pipelines and hence the best model suggested by TPOT at the end of the constrained time limit may not be the best model possible for that dataset. \n",
        "\n",
        "However, if sufficient time is given it will be somewhat closer to the best possible model. Some parameters are:\n",
        "\n",
        "- **max_time_mins**: how many minutes TPOT has to optimize the pipeline. If not None, this setting will override the generations parameter and allow TPOT to run until max_time_mins minutes elapse.\n",
        "- **max_eval_time_mins**: how many minutes TPOT has to evaluate a single pipeline. Setting this parameter to higher values will enable TPOT to evaluate more complex pipelines, but will also allow TPOT to run longer. Use this parameter to help prevent TPOT from wasting time on assessing time-consuming pipelines. The default is 5.\n",
        "- **early_stop**: how many generations TPOT checks whether there is no improvement in the optimization process. Ends the optimization process if there is no improvement in the given number of generations.\n",
        "- **n_jobs**: Number of procedures to use in parallel for evaluating pipelines during the TPOT optimization process. Setting n_jobs=-1 will use as many cores as available on the computer. Beware that using multiple methods on the same machine may cause memory issues for large datasets. The default is 1.\n",
        "- **subsample**: Fraction of training samples that are used during the TPOT optimization process. Must be in the range (0.0, 1.0]. The default is 1.\n",
        "\n",
        "Just for practice, you will again run TPOT with additional arguments max_time_mins = 10 and max_eval_time_mins = 0.04 but this time with reduced population_size = 15. If you do not want to wait hours for your TPOT model, this might be the way to go!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUH4u2cmJ0C8",
        "colab_type": "code",
        "outputId": "98bbbfd6-f50f-4931-b9e6-a3a04cf9d28b",
        "colab": {}
      },
      "source": [
        "tpot = TPOTClassifier(verbosity=2, max_time_mins=10, max_eval_time_mins=0.04, population_size=15)\n",
        "tpot.fit(tele.drop('class',axis=1).loc[training_indices].values, # X_train\n",
        "         tele.loc[training_indices,'class'].values) # y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.8281811731066163\n",
            "Generation 2 - Current best internal CV score: 0.8467575945563388\n",
            "Generation 3 - Current best internal CV score: 0.8654739243774452\n",
            "Generation 4 - Current best internal CV score: 0.8654739243774452\n",
            "Generation 5 - Current best internal CV score: 0.8654739243774452\n",
            "Generation 6 - Current best internal CV score: 0.8729749730857256\n",
            "Generation 7 - Current best internal CV score: 0.8729749730857256\n",
            "\n",
            "2.009534283333333 minutes have elapsed. TPOT will close down.\n",
            "TPOT closed prematurely. Will use the current best pipeline.\n",
            "\n",
            "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.5, max_depth=2, min_child_weight=15, n_estimators=100, nthread=1, subsample=0.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "        disable_update_check=False, early_stop=None, generations=1000000,\n",
              "        max_eval_time_mins=0.04, max_time_mins=2, memory=None,\n",
              "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "        periodic_checkpoint_folder=None, population_size=15,\n",
              "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
              "        verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00W9SeYmJ0C9",
        "colab_type": "text"
      },
      "source": [
        "As you can notice the best performing classifier within the time frame specified is now XGBoost with `SelectPercentile()` and `RobustScaler()` as the pre-processing steps. But you notice that the accurracy declined to 87.29%.\n",
        "\n",
        "After you trained your best model, you can always export the pipeline as a file and use it without any training (we know training takes a lot of time).\n",
        "\n",
        "You can export the above trained pipeline as (assume you have a `model` subfolder in your repo):\n",
        "```python\n",
        "tpot.export('tpot_exported_pipeline.py')\n",
        "```\n",
        "\n",
        "Then in your subsequent analysis, you can import this `.py` file and then use the `tpot.score()` method to evaluate/deploy the model on _new, unseen_ data.\n",
        "\n",
        "For more examples of using TPOT for machine learning, refer to [these examples](https://epistasislab.github.io/tpot/examples/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY6i4jlzJ0C-",
        "colab_type": "text"
      },
      "source": [
        "# Limitations\n",
        "\n",
        "- **TPOT can take a long time to finish its search**\n",
        "\n",
        "Running TPOT isnâ€™t as simple as fitting one model on the dataset. It is considering multiple machine learning algorithms (random forests, linear models, SVMs, etc.) in a pipeline with numerous preprocessing steps (missing value imputation, scaling, PCA, feature selection, etc.), the hyper-parameters for all of the models and preprocessing steps, as well as multiple ways to ensemble or stack the algorithms within the pipeline. Thatâ€™s why it usually takes a long time to execute and isnâ€™t feasible for large datasets.\n",
        "\n",
        "- **TPOT can recommend different solutions for the same dataset**\n",
        "\n",
        "If you're working with a reasonably complex dataset or run TPOT for a short amount of time, different TPOT runs may result in different pipeline recommendations. When two TPOT runs recommend different pipelines, this means that the TPOT runs didn't converge due to lack of time or that multiple pipelines perform more-or-less the same on your dataset. If that is the case, you can always use the __voting__ mechanism in the __ensemble learning__ to combine the models together.\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "Hurray! You have come to the end of this tutorial. You started with a little introduction about the idea behind Automated Machine Learning platforms. Then you explored a bit on Genetic Programming and how TPOT uses it to automate the machine learning pipeline building process. You also practiced using the TPOT library in Python on a dataset along with gaining knowledge about the functions it provides. If you plan to use TPOT in the future, I strongly suggest you look at its excellent [documentation](http://epistasislab.github.io/tpot/). Happy Exploring!\n",
        "\n",
        "If you would like to learn more about Machine Learning in Python, take DataCamp's [Machine Learning with Tree-Based Models in Python](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python) course.\n",
        "\n",
        "The following web pages were used as sources in writing this tutorial.\n",
        "\n",
        "- [Classification](http://epistasislab.github.io/tpot/api/)\n",
        "- [What to expect from AutoML software](https://epistasislab.github.io/tpot/using/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FgUVeGNJ0C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}